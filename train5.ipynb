{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 23:47:03.892800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 23:47:04.104870: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-18 23:47:04.871413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-04-18 23:47:04.871573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-04-18 23:47:04.871580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
    "# base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "base_model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# base_model=\"beomi/open-llama-2-ko-7b\"\n",
    "# base_model = \"huggingface-projects/llama-2-7b-chat\"\n",
    "# base_model = \"TinyPixel/Llama-2-7B-bf16-sharded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fine-tuned model\n",
    "# new_model = \"llama-2-7b-hf-fine-tuned-test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA 모델을 사용하기 위한 설정\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b6dc5c90404555a913029ff9c4aaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 라마2 모델 불러오기\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 로드\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # 토크나이저 병렬처리 방지(오류 방지)\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true' # __cell__ 오류 방지\n",
    "\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(\n",
    "    base_model,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token # 패딩 토큰을 문장의 끝으로 설정 </s>\n",
    "tokenizer.padding_side = \"right\" # 패딩을 문장 뒤에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 양식\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "file_name = 'preprocess/dataset3/new_ratings_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "input_file = file_name\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 불러온 데이터 확인\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Toy Story (1995)', 'rating': 4.0, 'imdbId': 'tt114709', 'timestamp': 964982703}, {'title': 'Grumpier Old Men (1995)', 'rating': 4.0, 'imdbId': 'tt113228', 'timestamp': 964981247}, {'title': 'Heat (1995)', 'rating': 4.0, 'imdbId': 'tt113277', 'timestamp': 964982224}, {'title': 'Seven (a.k.a. Se7en) (1995)', 'rating': 5.0, 'imdbId': 'tt114369', 'timestamp': 964983815}, {'title': 'Usual Suspects, The (1995)', 'rating': 5.0, 'imdbId': 'tt114814', 'timestamp': 964982931}, {'title': 'From Dusk Till Dawn (1996)', 'rating': 3.0, 'imdbId': 'tt116367', 'timestamp': 964982400}, {'title': 'Bottle Rocket (1996)', 'rating': 5.0, 'imdbId': 'tt115734', 'timestamp': 964980868}, {'title': 'Braveheart (1995)', 'rating': 4.0, 'imdbId': 'tt112573', 'timestamp': 964982176}, {'title': 'Rob Roy (1995)', 'rating': 5.0, 'imdbId': 'tt114287', 'timestamp': 964984041}, {'title': 'Canadian Bacon (1995)', 'rating': 5.0, 'imdbId': 'tt109370', 'timestamp': 964984100}]\n",
      "<class 'list'>\n",
      "{'title': 'Toy Story (1995)', 'rating': 4.0, 'imdbId': 'tt114709', 'timestamp': 964982703}\n",
      "<class 'dict'>\n",
      "[{'title': 'Canadian Bacon (1995)'}, {'title': 'Rob Roy (1995)'}, {'title': 'Seven (a.k.a. Se7en) (1995)'}, {'title': 'Usual Suspects, The (1995)'}, {'title': 'Bottle Rocket (1996)'}, {'title': 'Toy Story (1995)'}, {'title': 'Heat (1995)'}, {'title': 'Braveheart (1995)'}, {'title': 'Grumpier Old Men (1995)'}, {'title': 'From Dusk Till Dawn (1996)'}]\n"
     ]
    }
   ],
   "source": [
    "# print(data[1])\n",
    "\n",
    "print(data[0][\"ratings\"]) # 영화 평점들 정보 모음\n",
    "print(type(data[0][\"ratings\"])) \n",
    "\n",
    "print(data[0][\"ratings\"][0]) # 평점 1개\n",
    "print(type(data[0][\"ratings\"][0])) \n",
    "print(data[0][\"rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = '''\n",
    "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 매핑 함수 정의\n",
    "def map_data_to_format(example):\n",
    "\n",
    "    user_ratings_str = json.dumps(example['ratings'], ensure_ascii=False)\n",
    "    rank_list_str = json.dumps(example[\"rank\"], ensure_ascii=False)\n",
    "    \n",
    "    text = (\n",
    "        f\"###instruction:\\n{instruction}\\n\\n\"\n",
    "        f\"user_rating_information:\\n{user_ratings_str}\\n\\n\"\n",
    "        f\"###response:\\n{rank_list_str}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # completion은 모델이 생성해야 할 예상 출력을 포함함\n",
    "    # 여기서는 우선순위에 따라 정렬된 영화 imdb_id의 리스트를 반환합니다.\n",
    "    completion = f\"{{\\\"rank\\\": {rank_list_str}}}\"\n",
    "    \n",
    "    return {'text': text, 'completion': completion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "data = load_dataset('json', data_files=file_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['rank', 'userId', 'ratings'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['ratings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['order']) # [['tt109370', 'tt114287', 'tt114369', 'tt114814', 'tt115734', 'tt114709', 'tt113277', 'tt112573', 'tt113228', 'tt116367'], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['userId']) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898d9c8b31424ed8a45c07fd2f8496cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 매핑 적용\n",
    "mapped_data = data.map(map_data_to_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['rank', 'userId', 'ratings', 'text', 'completion'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(mapped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31362f83d65143ae96a19d1f8a54d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea1382ada8148ef8446bc26fe8a7048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 분할\n",
    "split_data = mapped_data.train_test_split(test_size=0.1)  # 10%를 테스트셋으로 사용\n",
    "\n",
    "train_set = split_data['train']\n",
    "eval_set = split_data['test']\n",
    "\n",
    "train_set = train_set.map(lambda samples: tokenizer(samples[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"), batched=True)\n",
    "eval_set = eval_set.map(lambda samples: tokenizer(samples[\"text\"], padding=True, truncation=True, return_tensors=\"pt\"), batched=True)\n",
    "\n",
    "# lora 파라미터 설정\n",
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['rank', 'userId', 'ratings', 'text', 'completion', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 90\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###instruction:\n",
      "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
      "\n",
      "user_rating_information:\n",
      "[{\"imdbId\": \"tt112697\", \"rating\": 3.0, \"timestamp\": 847434961, \"title\": \"Clueless (1995)\"}, {\"imdbId\": \"tt114814\", \"rating\": 4.0, \"timestamp\": 847434881, \"title\": \"Usual Suspects, The (1995)\"}, {\"imdbId\": \"tt110877\", \"rating\": 5.0, \"timestamp\": 847435238, \"title\": \"Postman, The (Postino, Il) (1994)\"}, {\"imdbId\": \"tt112573\", \"rating\": 4.0, \"timestamp\": 847434880, \"title\": \"Braveheart (1995)\"}, {\"imdbId\": \"tt112384\", \"rating\": 3.0, \"timestamp\": 847434748, \"title\": \"Apollo 13 (1995)\"}, {\"imdbId\": \"tt112462\", \"rating\": 3.0, \"timestamp\": 847434802, \"title\": \"Batman Forever (1995)\"}, {\"imdbId\": \"tt111797\", \"rating\": 4.0, \"timestamp\": 847435292, \"title\": \"Eat Drink Man Woman (Yin shi nan nu) (1994)\"}, {\"imdbId\": \"tt110005\", \"rating\": 5.0, \"timestamp\": 847435337, \"title\": \"Heavenly Creatures (1994)\"}, {\"imdbId\": \"tt110148\", \"rating\": 3.0, \"timestamp\": 847435292, \"title\": \"Interview with the Vampire: The Vampire Chronicles (1994)\"}, {\"imdbId\": \"tt110367\", \"rating\": 4.0, \"timestamp\": 847435238, \"title\": \"Little Women (1994)\"}]\n",
      "\n",
      "###response:\n",
      "[{\"title\": \"Heavenly Creatures (1994)\"}, {\"title\": \"Postman, The (Postino, Il) (1994)\"}, {\"title\": \"Eat Drink Man Woman (Yin shi nan nu) (1994)\"}, {\"title\": \"Little Women (1994)\"}, {\"title\": \"Usual Suspects, The (1995)\"}, {\"title\": \"Braveheart (1995)\"}, {\"title\": \"Interview with the Vampire: The Vampire Chronicles (1994)\"}, {\"title\": \"Clueless (1995)\"}, {\"title\": \"Batman Forever (1995)\"}, {\"title\": \"Apollo 13 (1995)\"}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<class 'str'>\n",
      "\n",
      "\n",
      "###instruction:\n",
      "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
      "\n",
      "user_rating_information:\n",
      "[{\"imdbId\": \"tt114508\", \"rating\": 3.0, \"timestamp\": 845553586, \"title\": \"Species (1995)\"}, {\"imdbId\": \"tt114663\", \"rating\": 3.0, \"timestamp\": 845556290, \"title\": \"Three Wishes (1995)\"}, {\"imdbId\": \"tt114781\", \"rating\": 3.0, \"timestamp\": 845553619, \"title\": \"Under Siege 2: Dark Territory (1995)\"}, {\"imdbId\": \"tt114798\", \"rating\": 3.0, \"timestamp\": 845555477, \"title\": \"Unstrung Heroes (1995)\"}, {\"imdbId\": \"tt114887\", \"rating\": 4.0, \"timestamp\": 845554024, \"title\": \"Walk in the Clouds, A (1995)\"}, {\"imdbId\": \"tt114898\", \"rating\": 3.0, \"timestamp\": 845553253, \"title\": \"Waterworld (1995)\"}, {\"imdbId\": \"tt114928\", \"rating\": 3.0, \"timestamp\": 845556106, \"title\": \"White Man's Burden (1995)\"}, {\"imdbId\": \"tt114938\", \"rating\": 4.0, \"timestamp\": 845556310, \"title\": \"Wild Bill (1995)\"}, {\"imdbId\": \"tt112602\", \"rating\": 4.0, \"timestamp\": 845556181, \"title\": \"Bushwhacked (1995)\"}, {\"imdbId\": \"tt112508\", \"rating\": 4.0, \"timestamp\": 845554099, \"title\": \"Billy Madison (1995)\"}]\n",
      "\n",
      "###response:\n",
      "[{\"title\": \"Wild Bill (1995)\"}, {\"title\": \"Bushwhacked (1995)\"}, {\"title\": \"Billy Madison (1995)\"}, {\"title\": \"Walk in the Clouds, A (1995)\"}, {\"title\": \"Three Wishes (1995)\"}, {\"title\": \"White Man's Burden (1995)\"}, {\"title\": \"Unstrung Heroes (1995)\"}, {\"title\": \"Under Siege 2: Dark Territory (1995)\"}, {\"title\": \"Species (1995)\"}, {\"title\": \"Waterworld (1995)\"}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_set[3][\"text\"])\n",
    "print(\"\\n\")\n",
    "print(type(train_set[3][\"text\"]))\n",
    "print(\"\\n\")\n",
    "# print(train_set[20][\"text\"])\n",
    "print(train_set[79][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###instruction:\n",
      "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
      "\n",
      "user_rating_information:\n",
      "[{\"imdbId\": \"tt87332\", \"rating\": 5.0, \"timestamp\": 964983414, \"title\": \"Ghostbusters (a.k.a. Ghost Busters) (1984)\"}, {\"imdbId\": \"tt129167\", \"rating\": 5.0, \"timestamp\": 964982703, \"title\": \"Iron Giant, The (1999)\"}, {\"imdbId\": \"tt94737\", \"rating\": 4.0, \"timestamp\": 964981710, \"title\": \"Big (1988)\"}, {\"imdbId\": \"tt120657\", \"rating\": 4.0, \"timestamp\": 964980523, \"title\": \"13th Warrior, The (1999)\"}, {\"imdbId\": \"tt169547\", \"rating\": 5.0, \"timestamp\": 964980868, \"title\": \"American Beauty (1999)\"}, {\"imdbId\": \"tt82348\", \"rating\": 5.0, \"timestamp\": 964981680, \"title\": \"Excalibur (1981)\"}, {\"imdbId\": \"tt31397\", \"rating\": 5.0, \"timestamp\": 964982703, \"title\": \"Gulliver's Travels (1939)\"}, {\"imdbId\": \"tt100802\", \"rating\": 4.0, \"timestamp\": 964982290, \"title\": \"Total Recall (1990)\"}, {\"imdbId\": \"tt61578\", \"rating\": 5.0, \"timestamp\": 964981872, \"title\": \"Dirty Dozen, The (1967)\"}, {\"imdbId\": \"tt58150\", \"rating\": 5.0, \"timestamp\": 964982176, \"title\": \"Goldfinger (1964)\"}]\n",
      "\n",
      "###response:\n",
      "[{\"title\": \"Ghostbusters (a.k.a. Ghost Busters) (1984)\"}, {\"title\": \"Iron Giant, The (1999)\"}, {\"title\": \"Gulliver's Travels (1939)\"}, {\"title\": \"Goldfinger (1964)\"}, {\"title\": \"Dirty Dozen, The (1967)\"}, {\"title\": \"Excalibur (1981)\"}, {\"title\": \"American Beauty (1999)\"}, {\"title\": \"Total Recall (1990)\"}, {\"title\": \"Big (1988)\"}, {\"title\": \"13th Warrior, The (1999)\"}]\n",
      "\n",
      "\n",
      "###instruction:\n",
      "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
      "\n",
      "user_rating_information:\n",
      "[{\"imdbId\": \"tt108550\", \"rating\": 5.0, \"timestamp\": 845553586, \"title\": \"What's Eating Gilbert Grape (1993)\"}, {\"imdbId\": \"tt114924\", \"rating\": 4.0, \"timestamp\": 845553253, \"title\": \"While You Were Sleeping (1995)\"}, {\"imdbId\": \"tt111667\", \"rating\": 4.0, \"timestamp\": 845555265, \"title\": \"War, The (1994)\"}, {\"imdbId\": \"tt110598\", \"rating\": 3.0, \"timestamp\": 845553938, \"title\": \"Muriel's Wedding (1994)\"}, {\"imdbId\": \"tt112435\", \"rating\": 3.0, \"timestamp\": 845555172, \"title\": \"Baby-Sitters Club, The (1995)\"}, {\"imdbId\": \"tt109040\", \"rating\": 3.0, \"timestamp\": 845553146, \"title\": \"Ace Ventura: Pet Detective (1994)\"}, {\"imdbId\": \"tt104779\", \"rating\": 3.0, \"timestamp\": 845555300, \"title\": \"Bitter Moon (1992)\"}, {\"imdbId\": \"tt109348\", \"rating\": 3.0, \"timestamp\": 845553938, \"title\": \"Bullets Over Broadway (1994)\"}, {\"imdbId\": \"tt109444\", \"rating\": 5.0, \"timestamp\": 845553146, \"title\": \"Clear and Present Danger (1994)\"}, {\"imdbId\": \"tt109446\", \"rating\": 5.0, \"timestamp\": 845553489, \"title\": \"Client, The (1994)\"}]\n",
      "\n",
      "###response:\n",
      "[{\"title\": \"What's Eating Gilbert Grape (1993)\"}, {\"title\": \"Client, The (1994)\"}, {\"title\": \"Clear and Present Danger (1994)\"}, {\"title\": \"War, The (1994)\"}, {\"title\": \"While You Were Sleeping (1995)\"}, {\"title\": \"Bitter Moon (1992)\"}, {\"title\": \"Baby-Sitters Club, The (1995)\"}, {\"title\": \"Muriel's Wedding (1994)\"}, {\"title\": \"Bullets Over Broadway (1994)\"}, {\"title\": \"Ace Ventura: Pet Detective (1994)\"}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval_set[3][\"text\"])\n",
    "# print(eval_set[20][\"text\"])\n",
    "print(eval_set[9][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rank\": [{\"title\": \"Heavenly Creatures (1994)\"}, {\"title\": \"Postman, The (Postino, Il) (1994)\"}, {\"title\": \"Eat Drink Man Woman (Yin shi nan nu) (1994)\"}, {\"title\": \"Little Women (1994)\"}, {\"title\": \"Usual Suspects, The (1995)\"}, {\"title\": \"Braveheart (1995)\"}, {\"title\": \"Interview with the Vampire: The Vampire Chronicles (1994)\"}, {\"title\": \"Clueless (1995)\"}, {\"title\": \"Batman Forever (1995)\"}, {\"title\": \"Apollo 13 (1995)\"}]}\n",
      "{\"rank\": [{\"title\": \"Wild Bill (1995)\"}, {\"title\": \"Bushwhacked (1995)\"}, {\"title\": \"Billy Madison (1995)\"}, {\"title\": \"Walk in the Clouds, A (1995)\"}, {\"title\": \"Three Wishes (1995)\"}, {\"title\": \"White Man's Burden (1995)\"}, {\"title\": \"Unstrung Heroes (1995)\"}, {\"title\": \"Under Siege 2: Dark Territory (1995)\"}, {\"title\": \"Species (1995)\"}, {\"title\": \"Waterworld (1995)\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(train_set[3][\"completion\"])\n",
    "# print(train_set[20][\"completion\"])\n",
    "print(train_set[79][\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_params)\n",
    "\n",
    "# prameter\n",
    "epochs = 1 # 10\n",
    "batch_size = 1\n",
    "lr = 2e-4\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"models5\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    logging_steps=20,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    "    dataloader_num_workers=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wandb login --relogin\n",
    "# torch.cuda.empty_cache()\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuadmin/anaconda3/envs/llm_test/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c2d06ff6a340af896901b7eb4adb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 80.4114, 'train_samples_per_second': 1.119, 'train_steps_per_second': 0.062, 'train_loss': 0.9120184898376464, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=0.9120184898376464, metrics={'train_runtime': 80.4114, 'train_samples_per_second': 1.119, 'train_steps_per_second': 0.062, 'train_loss': 0.9120184898376464, 'epoch': 0.89})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_params,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=eval_set,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "2024-04-19 10:49:37.915191: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2024-04-19 10:49:38.028882: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
       "2024-04-19 10:49:38.031520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:38.031540: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
       "2024-04-19 10:49:38.484253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:38.484318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:38.484325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
       "2024-04-19 10:49:39.230437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.230602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.230717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.233885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.234018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.234127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
       "2024-04-19 10:49:39.234151: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
       "Skipping registering GPU devices...\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 4000 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "log_dir = \"./models5\" \n",
    "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\"\n",
    "\n",
    "user_ratings_str = [{\"imdbId\": \"tt199725\", \"rating\": 3.0, \"timestamp\": 1044311397, \"title\": \"Love and Basketball (2000)\"}, {\"imdbId\": \"tt171359\", \"rating\": 3.0, \"timestamp\": 1044311426, \"title\": \"Hamlet (2000)\"}, {\"imdbId\": \"tt187393\", \"rating\": 3.0, \"timestamp\": 1044311108, \"title\": \"Patriot, The (2000)\"}, {\"imdbId\": \"tt181875\", \"rating\": 4.0, \"timestamp\": 1044311358, \"title\": \"Almost Famous (2000)\"}, {\"imdbId\": \"tt180093\", \"rating\": 5.0, \"timestamp\": 1044311310, \"title\": \"Requiem for a Dream (2000)\"}, {\"imdbId\": \"tt120917\", \"rating\": 4.0, \"timestamp\": 1044311744, \"title\": \"Emperor's New Groove, The (2000)\"}, {\"imdbId\": \"tt181865\", \"rating\": 5.0, \"timestamp\": 1044311310, \"title\": \"Traffic (2000)\"}, {\"imdbId\": \"tt209144\", \"rating\": 5.0, \"timestamp\": 1044311318, \"title\": \"Memento (2000)\"}, {\"imdbId\": \"tt125022\", \"rating\": 2.0, \"timestamp\": 1044311195, \"title\": \"Heartbreakers (2001)\"}, {\"imdbId\": \"tt203009\", \"rating\": 4.0, \"timestamp\": 1044311949, \"title\": \"Moulin Rouge (2001)\"}]\n",
    "\n",
    "# order_list_str=[\"tt118971\", \"tt118883\", \"tt120102\", \"tt119488\", \"tt118884\", \"tt119345\", \"tt119174\", \"tt120177\", \"tt118842\", \"tt120399\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "###instruction:\n",
      "I will sort the movie list in descending order based on user rating information. I will show the title for the corresponding movie. It must return in JSON format.\n",
      "\n",
      "\n",
      "user_rating_information:\n",
      "[{'imdbId': 'tt199725', 'rating': 3.0, 'timestamp': 1044311397, 'title': 'Love and Basketball (2000)'}, {'imdbId': 'tt171359', 'rating': 3.0, 'timestamp': 1044311426, 'title': 'Hamlet (2000)'}, {'imdbId': 'tt187393', 'rating': 3.0, 'timestamp': 1044311108, 'title': 'Patriot, The (2000)'}, {'imdbId': 'tt181875', 'rating': 4.0, 'timestamp': 1044311358, 'title': 'Almost Famous (2000)'}, {'imdbId': 'tt180093', 'rating': 5.0, 'timestamp': 1044311310, 'title': 'Requiem for a Dream (2000)'}, {'imdbId': 'tt120917', 'rating': 4.0, 'timestamp': 1044311744, 'title': \"Emperor's New Groove, The (2000)\"}, {'imdbId': 'tt181865', 'rating': 5.0, 'timestamp': 1044311310, 'title': 'Traffic (2000)'}, {'imdbId': 'tt209144', 'rating': 5.0, 'timestamp': 1044311318, 'title': 'Memento (2000)'}, {'imdbId': 'tt125022', 'rating': 2.0, 'timestamp': 1044311195, 'title': 'Heartbreakers (2001)'}, {'imdbId': 'tt203009', 'rating': 4.0, 'timestamp': 1044311949, 'title': 'Moulin Rouge (2001)'}]\n",
      "\n",
      "\n",
      "###output:\n",
      "[\n",
      "{\"title\": \"Memento (2000)\", \"rating\": 5.0},\n",
      "{\"title\": \"Almost Famous (2000)\", \"rating\": 4.0},\n",
      "{\"title\": \"Traffic (2000)\", \"rating\": 5.0},\n",
      "{\"title\": \"Love and Basketball (2000)\", \"rating\": 3.0},\n",
      "{\"title\": \"Patriot, The (2000)\", \"rating\": 3.0},\n",
      "{\"title\": \"Hamlet (2000)\", \"rating\": 3.0},\n",
      "{\"title\": \"Requiem for a Dream (2000)\", \"rating\": 5.0},\n",
      "{\"title\": \"Emperor's New Groove, The (2000)\", \"rating\": 4.0},\n",
      "{\"title\": \"Heartbreakers (2001)\", \"rating\": 2.0}\n",
      "]\n",
      "\n",
      "\n",
      "###Explanation:\n",
      "The function takes in the `user_rating_information` list and sorts the movies in descending order based on their ratings. The function\n"
     ]
    }
   ],
   "source": [
    "# ###instruction:\n",
    "# {instruction}\n",
    "\n",
    "text = f'''\n",
    "###instruction:\n",
    "{instruction}\n",
    "\n",
    "\n",
    "user_rating_information:\n",
    "{user_ratings_str}\n",
    "\n",
    "\n",
    "'''\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"].to(\"cuda\"), \n",
    "    attention_mask=inputs[\"attention_mask\"], \n",
    "    max_new_tokens=256,\n",
    "    early_stopping=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "output = tokenizer.decode(outputs[0])\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_rec_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
